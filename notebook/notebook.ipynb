{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c86a9c7",
   "metadata": {},
   "source": [
    "# ML Zoomcamp - Midterm Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60e6d0d",
   "metadata": {},
   "source": [
    "For the ml-zoomcamp midterm project I've chosen to train a classifier model\n",
    "that predicts the presence or absence of heart disease based on a series of attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f2c8be",
   "metadata": {},
   "source": [
    "## Dataset : UCI Heart Disease Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0ea763",
   "metadata": {},
   "source": [
    "The dataset used is a subset of the Heart Disease Data Set from UCI Machine Learning data repository. It contains 14 patient attributes and I'll use them to predict whether a patient has heart disease (target values 1,2,3,4) or not (target value 0).\n",
    "\n",
    "The dataset is included in the project directory, or can be downloaded from kaggle:\n",
    "\n",
    "[https://www.kaggle.com/datasets/redwankarimsony/heart-disease-data/download?datasetVersionNumber=6](https://www.kaggle.com/datasets/redwankarimsony/heart-disease-data/download?datasetVersionNumber=6)\n",
    "\n",
    "The feature names are:\n",
    "\n",
    "0. **id**\n",
    "1. **age**\n",
    "2. **sex**\n",
    "3. **dataset**: the Cleveland database is the only one used\n",
    "4. **cp**: chest pain type\n",
    "    - typical angina\n",
    "    - atypical angina\n",
    "    - non-anginal pain\n",
    "    - asymptomatic\n",
    "5. **trestbps**: resting blood pressure (in mm Hg on admission to the hospital)\n",
    "6. **chol**: serum cholestoral in mg/dl\n",
    "7. **fbs**: (fasting blood sugar > 120 mg/dl) (1 = true; 0 = false)\n",
    "8. **restecg**: resting electrocardiographic results\n",
    "    - normal\n",
    "    - lv hypertrophy\t\n",
    "    - st-t abnormality\n",
    "9. **thalach**: maximum heart rate achieved\n",
    "10. **exang**: exercise induced angina\n",
    "11. **oldpeak**: ST depression induced by exercise relative to rest\n",
    "12. **slope**: the slope of the peak exercise ST segment\n",
    "    - upsloping\n",
    "    - flat\n",
    "    - downsloping\n",
    "13. **ca**: number of major vessels (0-3) colored by flourosopy\n",
    "14. **thal**:\n",
    "    - normal\n",
    "    - fixed defect\n",
    "    - reversable defect\n",
    "15. **num**: the predicted target\n",
    "    - normal = 0\n",
    "    - heart disease = 1,2,3,4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26bd9566",
   "metadata": {},
   "source": [
    "## Data preparation and exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "5e8b179d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b810aa",
   "metadata": {},
   "source": [
    "After downloading the dataset, I imported it with pandas\n",
    "to inspect the features and possible missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "76f7d9c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>dataset</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalch</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>Male</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>typical angina</td>\n",
       "      <td>145.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>True</td>\n",
       "      <td>lv hypertrophy</td>\n",
       "      <td>150.0</td>\n",
       "      <td>False</td>\n",
       "      <td>2.3</td>\n",
       "      <td>downsloping</td>\n",
       "      <td>0.0</td>\n",
       "      <td>fixed defect</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>67</td>\n",
       "      <td>Male</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>asymptomatic</td>\n",
       "      <td>160.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>False</td>\n",
       "      <td>lv hypertrophy</td>\n",
       "      <td>108.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1.5</td>\n",
       "      <td>flat</td>\n",
       "      <td>3.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>67</td>\n",
       "      <td>Male</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>asymptomatic</td>\n",
       "      <td>120.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>False</td>\n",
       "      <td>lv hypertrophy</td>\n",
       "      <td>129.0</td>\n",
       "      <td>True</td>\n",
       "      <td>2.6</td>\n",
       "      <td>flat</td>\n",
       "      <td>2.0</td>\n",
       "      <td>reversable defect</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>37</td>\n",
       "      <td>Male</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>non-anginal</td>\n",
       "      <td>130.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>False</td>\n",
       "      <td>normal</td>\n",
       "      <td>187.0</td>\n",
       "      <td>False</td>\n",
       "      <td>3.5</td>\n",
       "      <td>downsloping</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>41</td>\n",
       "      <td>Female</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>atypical angina</td>\n",
       "      <td>130.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>False</td>\n",
       "      <td>lv hypertrophy</td>\n",
       "      <td>172.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.4</td>\n",
       "      <td>upsloping</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  age     sex    dataset               cp  trestbps   chol    fbs  \\\n",
       "0   1   63    Male  Cleveland   typical angina     145.0  233.0   True   \n",
       "1   2   67    Male  Cleveland     asymptomatic     160.0  286.0  False   \n",
       "2   3   67    Male  Cleveland     asymptomatic     120.0  229.0  False   \n",
       "3   4   37    Male  Cleveland      non-anginal     130.0  250.0  False   \n",
       "4   5   41  Female  Cleveland  atypical angina     130.0  204.0  False   \n",
       "\n",
       "          restecg  thalch  exang  oldpeak        slope   ca  \\\n",
       "0  lv hypertrophy   150.0  False      2.3  downsloping  0.0   \n",
       "1  lv hypertrophy   108.0   True      1.5         flat  3.0   \n",
       "2  lv hypertrophy   129.0   True      2.6         flat  2.0   \n",
       "3          normal   187.0  False      3.5  downsloping  0.0   \n",
       "4  lv hypertrophy   172.0  False      1.4    upsloping  0.0   \n",
       "\n",
       "                thal  num  \n",
       "0       fixed defect    0  \n",
       "1             normal    2  \n",
       "2  reversable defect    1  \n",
       "3             normal    0  \n",
       "4             normal    0  "
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../heart_disease_uci.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "46bd9fd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'age', 'sex', 'dataset', 'cp', 'trestbps', 'chol', 'fbs',\n",
       "       'restecg', 'thalch', 'exang', 'oldpeak', 'slope', 'ca', 'thal', 'num'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2eb5805",
   "metadata": {},
   "source": [
    "Column names are all lower case and contain no spaces."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af65ef3",
   "metadata": {},
   "source": [
    "When checking for missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "8acbd596",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id            0\n",
       "age           0\n",
       "sex           0\n",
       "dataset       0\n",
       "cp            0\n",
       "trestbps     59\n",
       "chol         30\n",
       "fbs          90\n",
       "restecg       2\n",
       "thalch       55\n",
       "exang        55\n",
       "oldpeak      62\n",
       "slope       309\n",
       "ca          611\n",
       "thal        486\n",
       "num           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6462611b",
   "metadata": {},
   "source": [
    "There are missing values in several columns, so I decide to impute NaNs in the columns with less than 50% of missing values.\n",
    "- For categorical features, I manually find the most common value with `value_counts()`.\n",
    "- For numerical features, I impute NaN values with the median.\n",
    "\n",
    "I don't think it makes sense to keep columns where values are missing in more than 50% of the rows,\n",
    "so I delete them from the dataframe.\n",
    "The `id` column doesn't provide any useful information either, so I delete it too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "33ad46ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 920 entries, 0 to 919\n",
      "Data columns (total 13 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       920 non-null    int64  \n",
      " 1   sex       920 non-null    object \n",
      " 2   dataset   920 non-null    object \n",
      " 3   cp        920 non-null    object \n",
      " 4   trestbps  920 non-null    float64\n",
      " 5   chol      920 non-null    float64\n",
      " 6   fbs       920 non-null    bool   \n",
      " 7   restecg   920 non-null    object \n",
      " 8   thalch    920 non-null    float64\n",
      " 9   exang     920 non-null    bool   \n",
      " 10  oldpeak   920 non-null    float64\n",
      " 11  slope     920 non-null    object \n",
      " 12  num       920 non-null    int64  \n",
      "dtypes: bool(2), float64(4), int64(2), object(5)\n",
      "memory usage: 81.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df[\"fbs\"].fillna(False, inplace=True)\n",
    "df[\"restecg\"].fillna(\"normal\", inplace=True)\n",
    "df[\"exang\"].fillna(False, inplace=True)\n",
    "df[\"slope\"].fillna(\"flat\", inplace=True)\n",
    "\n",
    "numerical_nans = [\"trestbps\", \"chol\", \"thalch\", \"oldpeak\"]\n",
    "for col in numerical_nans:\n",
    "    median = df[col].median()\n",
    "    df[col].fillna(median, inplace=True)\n",
    "\n",
    "del df[\"id\"]\n",
    "del df[\"ca\"]\n",
    "del df[\"thal\"]\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "f2b6f762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    411\n",
       "1    265\n",
       "2    109\n",
       "3    107\n",
       "4     28\n",
       "Name: num, dtype: int64"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.num.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aedd8a3",
   "metadata": {},
   "source": [
    "There are 5 unique values in the target column `num`: 0 indicates that the patient has no heart disease\n",
    "and 1,2,3,4 indicate the presence of heart disease to various degrees of severity.\n",
    "\n",
    "My objective is to train a model for binary classification to predict whether a patient has a heart disease or not. In order to convert the target into a binary column, the values that indicate the presence of disease are all turned into 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "4c387348",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lf/3_22z6ms1hscctw3lvvwn5q80000gn/T/ipykernel_4032/4041446238.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.num.loc[df.num != 0] = 1\n"
     ]
    }
   ],
   "source": [
    "df.num.loc[df.num != 0] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc4d1dd",
   "metadata": {},
   "source": [
    "And I change the target column name to something more descriptive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "a3f88d9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    509\n",
       "0    411\n",
       "Name: disease, dtype: int64"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"disease\"] = df.num\n",
    "df.drop(\"num\", axis=1, inplace=True)\n",
    "df.disease.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1c1ab3",
   "metadata": {},
   "source": [
    "The dataset is balanced!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c083e93",
   "metadata": {},
   "source": [
    "## Setting up the validation framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "41b71f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "e7a3a917",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_train, df_test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "df_train, df_val = train_test_split(df_full_train, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "17ec59f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.reset_index(drop=True)\n",
    "df_val = df_val.reset_index(drop=True)\n",
    "df_test = df_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "5838bcde",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train.disease.values\n",
    "y_val = df_val.disease.values\n",
    "y_test = df_test.disease.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "d0341b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.drop(\"disease\", axis=1, inplace=True)\n",
    "df_val.drop(\"disease\", axis=1, inplace=True)\n",
    "df_test.drop(\"disease\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d057ce",
   "metadata": {},
   "source": [
    "## Feature importance analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08685168",
   "metadata": {},
   "source": [
    "### Feature importance of categorical columns: mutual information score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "749aeb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mutual_info_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "609d4489",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = [\"sex\", \"dataset\", \"cp\", \"fbs\", \"restecg\", \"exang\", \"slope\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "5a0ad4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutual_info_disease_score(series):\n",
    "    return mutual_info_score(series, df_full_train.disease)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "5e9fdabf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cp         0.147004\n",
       "exang      0.097273\n",
       "dataset    0.091677\n",
       "sex        0.060734\n",
       "slope      0.022916\n",
       "restecg    0.007835\n",
       "fbs        0.005028\n",
       "dtype: float64"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mi = df_full_train[categorical].apply(mutual_info_disease_score)\n",
    "mi.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa960f6",
   "metadata": {},
   "source": [
    "### Feature importance of numerical columns: correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "bed64164",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical = ['age', 'trestbps', 'chol', 'thalch', 'oldpeak']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "67416fc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "thalch      0.385894\n",
       "oldpeak     0.369913\n",
       "age         0.256861\n",
       "chol        0.236068\n",
       "trestbps    0.099594\n",
       "dtype: float64"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full_train[numerical].corrwith(df_full_train.disease).abs().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4e77a2",
   "metadata": {},
   "source": [
    "## Model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967254ca",
   "metadata": {},
   "source": [
    "To select the best model for this classification task,\n",
    "I first train the following models with their default settings and compare their ROC AUC scores:\n",
    "- Logistic Regression\n",
    "- Decision Tree\n",
    "- Random Forest\n",
    "- XG Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "86d25cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe80e905",
   "metadata": {},
   "source": [
    "The training and validation dataframes are vectorized in order to encode the categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "3bae217c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dict = df_train[categorical + numerical].to_dict(orient='records')\n",
    "val_dict = df_val[categorical + numerical].to_dict(orient='records')\n",
    "\n",
    "dv = DictVectorizer(sparse=False)\n",
    "\n",
    "X_train = dv.fit_transform(train_dict)\n",
    "X_val = dv.transform(val_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "6e578341",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(max_iter=1500)\n",
    "dt = DecisionTreeClassifier()\n",
    "rf = RandomForestClassifier(random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "3323b5bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-16 {color: black;background-color: white;}#sk-container-id-16 pre{padding: 0;}#sk-container-id-16 div.sk-toggleable {background-color: white;}#sk-container-id-16 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-16 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-16 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-16 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-16 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-16 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-16 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-16 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-16 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-16 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-16 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-16 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-16 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-16 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-16 div.sk-item {position: relative;z-index: 1;}#sk-container-id-16 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-16 div.sk-item::before, #sk-container-id-16 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-16 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-16 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-16 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-16 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-16 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-16 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-16 div.sk-label-container {text-align: center;}#sk-container-id-16 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-16 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-16\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" checked><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(random_state=1)"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg.fit(X_train, y_train)\n",
    "dt.fit(X_train, y_train)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "764aa51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_log_reg = log_reg.predict_proba(X_val)[:, 1]\n",
    "y_pred_dt = dt.predict_proba(X_val)[:, 1]\n",
    "y_pred_rf = rf.predict_proba(X_val)[:, 1]\n",
    "auc_log_reg = roc_auc_score(y_val, y_pred_log_reg)\n",
    "auc_dt = roc_auc_score(y_val, y_pred_dt)\n",
    "auc_rf = roc_auc_score(y_val, y_pred_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "78b4d4cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic regression roc_auc: 0.9147619047619047\n",
      "decision tree roc_auc: 0.726190476190476\n",
      "random forest roc_auc: 0.8972619047619048\n"
     ]
    }
   ],
   "source": [
    "print(\"logistic regression roc_auc:\", auc_log_reg)\n",
    "print(\"decision tree roc_auc:\", auc_dt)\n",
    "print(\"random forest roc_auc:\", auc_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "f84a641f",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = dv.get_feature_names_out()\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train, feature_names=features)\n",
    "dval = xgb.DMatrix(X_val, label=y_val, feature_names=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "b6fa250a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost roc_auc: 0.8803571428571428\n"
     ]
    }
   ],
   "source": [
    "xgb_params = {\n",
    "    'eta': 0.3, \n",
    "    'max_depth': 6,\n",
    "    'min_child_weight': 1,\n",
    "    \n",
    "    'objective': 'binary:logistic',\n",
    "    'nthread': 8,\n",
    "    \n",
    "    'seed': 1,\n",
    "    'verbosity': 1,\n",
    "}\n",
    "\n",
    "model_xgb = xgb.train(xgb_params, dtrain, num_boost_round=10)\n",
    "y_pred_xgb = model_xgb.predict(dval)\n",
    "auc_xgb = roc_auc_score(y_val, y_pred_xgb)\n",
    "print(\"XGBoost roc_auc:\", auc_xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae90765",
   "metadata": {},
   "source": [
    "## Model fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de036fe",
   "metadata": {},
   "source": [
    "Logistic regression has the best ROC AUC score,\n",
    "so I experiment with different parameters to see if the result can be improved. The default solver is changed to `'liblinear'` to be able to test `'l1'` and `'l2'` penalties.\n",
    "\n",
    "The parameters tested are regularization and penalty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "014b9561",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>regularization</th>\n",
       "      <th>penalty</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.699643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.827143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.010</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.797024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.010</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.886786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.100</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.899524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.100</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.911071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.500</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.919524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.500</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.915000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.000</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.918333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.000</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.915000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.000</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.915357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5.000</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.915000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10.000</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.914048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>10.000</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.913929</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    regularization penalty       auc\n",
       "0            0.001      l1  0.699643\n",
       "1            0.001      l2  0.827143\n",
       "2            0.010      l1  0.797024\n",
       "3            0.010      l2  0.886786\n",
       "4            0.100      l1  0.899524\n",
       "5            0.100      l2  0.911071\n",
       "6            0.500      l1  0.919524\n",
       "7            0.500      l2  0.915000\n",
       "8            1.000      l1  0.918333\n",
       "9            1.000      l2  0.915000\n",
       "10           5.000      l1  0.915357\n",
       "11           5.000      l2  0.915000\n",
       "12          10.000      l1  0.914048\n",
       "13          10.000      l2  0.913929"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = []\n",
    "\n",
    "for c in [0.001, 0.01, 0.1, 0.5, 1, 5, 10]:\n",
    "    for p in ['l1', 'l2']:\n",
    "        log_reg = LogisticRegression(C=c, solver='liblinear', penalty=p, max_iter=1500)\n",
    "        log_reg.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = log_reg.predict_proba(X_val)[:, 1]\n",
    "        auc = roc_auc_score(y_val, y_pred)\n",
    "\n",
    "        scores.append((c, p, auc))\n",
    "        \n",
    "columns = ['regularization', 'penalty', 'auc']\n",
    "df_scores = pd.DataFrame(scores, columns=columns)\n",
    "df_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ab06f8",
   "metadata": {},
   "source": [
    "The result is slightly improved by using `'l1'` penalty with the default regularization of `C=1.0`.\n",
    "\n",
    "I now train this model with the full training dataset (df_train + df_val) and test it with the held out data (df_test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "6aae4c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic regression roc_auc: 0.8988379204892967\n"
     ]
    }
   ],
   "source": [
    "df_full_train = df_full_train.reset_index(drop=True)\n",
    "y_train = df_full_train.disease.values\n",
    "\n",
    "train_dict = df_full_train[categorical + numerical].to_dict(orient='records')\n",
    "test_dict = df_test[categorical + numerical].to_dict(orient='records')\n",
    "\n",
    "dv = DictVectorizer(sparse=False)\n",
    "\n",
    "X_train = dv.fit_transform(train_dict)\n",
    "X_test = dv.transform(test_dict)\n",
    "\n",
    "log_reg = LogisticRegression(max_iter=1500, solver='liblinear', penalty='l1')\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = log_reg.predict_proba(X_test)[:, 1]\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "print(\"logistic regression roc_auc:\", auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2c2128",
   "metadata": {},
   "source": [
    "I also test a `'lbfgs'`\n",
    " solver with both allowed penalties to see if it offers a better result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "2930424d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>penalty</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>none</td>\n",
       "      <td>0.894679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>l2</td>\n",
       "      <td>0.895902</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  penalty       auc\n",
       "0    none  0.894679\n",
       "1      l2  0.895902"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = []\n",
    "for p in ['none', 'l2']:\n",
    "    log_reg = LogisticRegression(max_iter=1500, solver='lbfgs', penalty=p)\n",
    "    log_reg.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = log_reg.predict_proba(X_test)[:, 1]\n",
    "    auc = roc_auc_score(y_test, y_pred)\n",
    "    \n",
    "    scores.append((p, auc))\n",
    "\n",
    "columns = ['penalty', 'auc']\n",
    "df_scores = pd.DataFrame(scores, columns=columns)\n",
    "df_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518116f7",
   "metadata": {},
   "source": [
    "The best results seem to come from a Logistic Regression model with a `'liblinear'` solver and `L1` penalty.\n",
    "I now train the model with the full training set and test it with the hold out test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "d745a2fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic regression roc_auc: 0.8988379204892967\n"
     ]
    }
   ],
   "source": [
    "df_full_train = df_full_train.reset_index(drop=True)\n",
    "y_train = df_full_train.disease.values\n",
    "\n",
    "train_dict = df_full_train[categorical + numerical].to_dict(orient='records')\n",
    "test_dict = df_test[categorical + numerical].to_dict(orient='records')\n",
    "\n",
    "dv = DictVectorizer(sparse=False)\n",
    "\n",
    "X_train = dv.fit_transform(train_dict)\n",
    "X_test = dv.transform(test_dict)\n",
    "\n",
    "log_reg = LogisticRegression(max_iter=1500, solver='liblinear', penalty='l1')\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = log_reg.predict_proba(X_test)[:, 1]\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "print(\"logistic regression roc_auc:\", auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877241c2",
   "metadata": {},
   "source": [
    "The model has a good result with unseen testing data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ac80e7",
   "metadata": {},
   "source": [
    "## Saving the best model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7531d09",
   "metadata": {},
   "source": [
    "I will use BentoML to save and test the model API locally and then containerize and deploy it to AWS Elastic Container Service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "5a2727c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bentoml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "e587af8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(tag=\"heart_disease_model:7apds5s6s25s3ahg\", path=\"/Users/nineve/bentoml/models/heart_disease_model/7apds5s6s25s3ahg/\")"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bentoml.sklearn.save_model('heart_disease_model', log_reg, custom_objects={\"dictVectorizer\" : dv})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1281771e",
   "metadata": {},
   "source": [
    "The code to train and save the model is converted to a Python file `train.py` and then cleaned up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "07150695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook notebook.ipynb to script\n",
      "[NbConvertApp] Writing 11325 bytes to notebook.py\n"
     ]
    }
   ],
   "source": [
    "# !jupyter nbconvert --to script notebook.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c112c7bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "dd99106a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'Normal heart'}"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "data={\n",
    "    \"sex\": \"Female\",\n",
    "    \"dataset\": \"Hungary\",\n",
    "    \"cp\": \"atypical angina\",\n",
    "    \"fbs\": \"False\",\n",
    "    \"restecg\": \"st-t abnormality\",\n",
    "    \"exang\": \"False\",\n",
    "    \"slope\": \"flat\",\n",
    "    \"age\": 31,\n",
    "    \"trestbps\": 100.0,\n",
    "    \"chol\": 219.0,\n",
    "    \"thalch\": 150.0,\n",
    "    \"oldpeak\": 0.0\n",
    "}\n",
    "\n",
    "requests.post(\n",
    "   \"http://localhost:3000/classify\",\n",
    "   headers={\"content-type\": \"application/json\"},\n",
    "   json=data,\n",
    ").json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4547af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter nbconvert --to script notebook.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add855c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
